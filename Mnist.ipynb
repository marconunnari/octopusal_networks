{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with octopusal networks\n",
    "\n",
    "If you haven't already, I suggest you to read [the description of octopusal networks](https://nbviewer.jupyter.org/github/marconunnari/octopusal_networks/blob/master/OctopusalNetworks.ipynb).\n",
    "\n",
    "In this notebook we use octopusal networks to recognize handwritten digits contained in the [MINST database](https://en.wikipedia.org/wiki/MNIST_database).\n",
    "\n",
    "To achieve these, the strategy that has proved most successful is to use the convolutional base of a [Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network) to extract features from the images and then give these features to an octopusal network that will classify them.\n",
    "\n",
    "This may seem cheating but I think that before that the information arrive to the mind it is processed by some filters in the senses or somewhere else. So the convolution base in this example would act as the sensory system.\n",
    "\n",
    "At the end we get a result of 86% accuracy by training the model only on 500 training examples and without tuning very well the hyperparameters. The goal is just to show how an octopusal network can recognize patterns given some features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network\n",
    "\n",
    "Here we train a simple convolutional neural network with keras that get to 99% of accuracy on the MNIST and then save the model to a file. Uncomment the last line to generate the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "def train_conv_nn():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    from keras.datasets import mnist\n",
    "    from keras.utils import to_categorical\n",
    "\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "    train_images = train_images.astype('float32') / 255\n",
    "\n",
    "    test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "    test_images = test_images.astype('float32') / 255\n",
    "\n",
    "    train_labels = to_categorical(train_labels)\n",
    "    test_labels = to_categorical(test_labels)\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "    model.save('./cnn_minst.h5')\n",
    "    \n",
    "#train_conv_nn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction\n",
    "\n",
    "Here we take the convolutional base of the model trained (so without the densely connected layers) and feed it with the original images of the digits. Then we convert the features extracted in a clause 'where' usable by the octopusal network.\n",
    "\n",
    "The main function here is 'extract_data' that returns an object where we store the train and test datasets in a useful fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.models import load_model\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "model = load_model('./cnn_minst.h5')\n",
    "layer_name = 'flatten_1'\n",
    "conv_base = Model(inputs=model.input,\n",
    "                             outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "\n",
    "def features_to_where(features, threshold):\n",
    "    where = []\n",
    "    for i in range(0, len(features)):\n",
    "        value = features[i]\n",
    "        if (value > threshold):\n",
    "            where.append((0, i))\n",
    "    return where\n",
    "\n",
    "\n",
    "def show_image(image, label):\n",
    "    plt.title(f'Image: {label}')\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class MnistDataItem:\n",
    "    def __init__(self, image, label, where):\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "        self.where = where\n",
    "\n",
    "\n",
    "class MnistDataSet:\n",
    "    def __init__(self, size, images, labels, wheres):\n",
    "        self.size = size\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.wheres = wheres\n",
    "\n",
    "    def get_item(self, index):\n",
    "        return MnistDataItem(\n",
    "            self.images[index],\n",
    "            self.labels[index],\n",
    "            self.wheres[index]\n",
    "        )\n",
    "\n",
    "\n",
    "class MnistData:\n",
    "    def __init__(self, train, test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "\n",
    "\n",
    "def extract_features(images, labels, size, threshold):\n",
    "    images_mod = images.reshape((images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "    wheres = []\n",
    "    for index in range(0, size):\n",
    "        label = labels[index]\n",
    "        image = images[index]\n",
    "\n",
    "        image_mod = images_mod[index]\n",
    "\n",
    "        features = conv_base.predict(image_mod[None, :, :, :])\n",
    "        features = features * 100\n",
    "        features = features.astype(int)\n",
    "        features = features.reshape((576))\n",
    "\n",
    "        where = features_to_where(features, threshold)\n",
    "        wheres.append(where)\n",
    "    return MnistDataSet(size, images[:size], labels[:size], wheres)\n",
    "\n",
    "    \n",
    "def extract_data(size_train, size_test):\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    train = extract_features(train_images, train_labels, size_train, 50)\n",
    "    test = extract_features(test_images, test_labels, size_test, 50)\n",
    "    return MnistData(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Octopusal Network\n",
    "\n",
    "To classify the MNIST we introduce a new type of architecture of the beach: the BeachWithHemispheres. In this class we don't connect the octopuses neighbours, but we divide the beach in two parts and we connect each octopus of the first part to each octopus on the other part. We also introduce the concept of 'freeze_connections' that if activated will prevent the soreness of a tentacle to increase (this is useful in the test stage when we don't want to train the network anymore)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octopusal_networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TentacleWithFreezing(TentacleWithSoreness):\n",
    "\n",
    "    freeze_connections = False\n",
    "\n",
    "    def __init__(self, id, owner, connected):\n",
    "        super().__init__(id, owner, connected)\n",
    "\n",
    "    def shock(self):\n",
    "        if self.connected.awake:\n",
    "            if not TentacleWithFreezing.freeze_connections:\n",
    "                self.soreness += 1\n",
    "        else:\n",
    "            self.connected.shocked(self.soreness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeachWithHemispheres(BeachWithListeners):\n",
    "\n",
    "    def __init__(self, width, height, shocks_threshold=80,\n",
    "                 smell_threshold=50, tiredness_threshold=5, recovery_threshold=5):\n",
    "        super().__init__(width, height, shocks_threshold, smell_threshold,\n",
    "                         tiredness_threshold, recovery_threshold)\n",
    "        self.divide_hemispheres()\n",
    "        self.connect_hemispheres()\n",
    "\n",
    "    def connect_neighbours(self):\n",
    "        pass\n",
    "\n",
    "    def create_tentacle(self, id, owner, connected):\n",
    "        return TentacleWithFreezing(id=id, owner=owner, connected=connected)\n",
    "\n",
    "    def divide_hemispheres(self):\n",
    "        half_row = self.height // 2\n",
    "        half_index = half_row * self.width\n",
    "        self.hemisphere1 = self.octopuses[:half_index]\n",
    "        self.hemisphere2 = self.octopuses[half_index:]\n",
    "\n",
    "    def connect_hemispheres(self):\n",
    "        i = 0\n",
    "        for octopus1 in self.hemisphere1:\n",
    "            for octopus2 in self.hemisphere2:\n",
    "                tentacle = self.create_tentacle(id=i, owner=octopus1, connected=octopus2)\n",
    "                i += 1\n",
    "    \n",
    "    def animate(self, where=None, iterations=10, show=True, freeze_connections=False):\n",
    "        TentacleWithFreezing.freeze_connections = freeze_connections\n",
    "        super().animate(where, iterations, show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training stage\n",
    "\n",
    "To recognize the digits we instatiate a beach with two rows. The first row is the first hemisphere on which we'll show the features. The second row is the second hemisphere where we assign the first 50 octopuses to the recognition of the digit zero, the second 50 octopuses to the recognition of the digit two and so on.\n",
    "\n",
    "So for each training example we activate the beach with the features of the digit and the corresponding zone on the second hemisphere. In this way we connect the inputs with the expected outputs.\n",
    "\n",
    "Eventually we attach a listener to each zone of the second hemisphere that will determine the prediction by detecting which digit pattern was awakened first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 500\n",
      "  100% [=================================================================] Time elapsed: 342.40s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from progress_bar import ProgressBar\n",
    "\n",
    "mnist_data = extract_data(500, 250)\n",
    "\n",
    "beach = BeachWithHemispheres(\n",
    "    width=576, height=2,\n",
    "    shocks_threshold=150000,\n",
    "    tiredness_threshold=50,\n",
    "    smell_threshold=200,\n",
    ")\n",
    "\n",
    "second_row = [(1, y) for y in range(0, 576)]\n",
    "zero = second_row[0:50]\n",
    "one = second_row[50:100]\n",
    "two = second_row[100:150]\n",
    "three = second_row[150:200]\n",
    "four = second_row[200:250]\n",
    "five = second_row[250:300]\n",
    "six = second_row[300:350]\n",
    "seven = second_row[350:400]\n",
    "eight = second_row[400:450]\n",
    "nine = second_row[450:500]\n",
    "digits = [zero, one, two, three, four, five, six, seven, eight, nine]\n",
    "\n",
    "dataset = mnist_data.train\n",
    "print(f\"Training examples: {dataset.size}\")\n",
    "pb = ProgressBar(dataset.size)\n",
    "time_start = time.time()\n",
    "for index in range(0, dataset.size):\n",
    "    item = dataset.get_item(index)\n",
    "    digit = digits[item.label]\n",
    "    beach.animate(item.where + digit, iterations=10, show=False)\n",
    "    beach.night(show=False)\n",
    "    pb += 1\n",
    "time_elapsed = time.time() - time_start\n",
    "print(f\" Time elapsed: {time_elapsed:.2f}s\")\n",
    "del pb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitListener():\n",
    "\n",
    "    threshold = 50\n",
    "    winner = None\n",
    "\n",
    "    def __init__(self, digit):\n",
    "        self.digit = digit\n",
    "        self.threshold = DigitListener.threshold\n",
    "\n",
    "    def reset(self):\n",
    "        DigitListener.winner = None\n",
    "        self.threshold = DigitListener.threshold\n",
    "\n",
    "    def fire(self, octopus):\n",
    "        if octopus.awake:\n",
    "            self.threshold -= 1\n",
    "        if (self.threshold == 0):\n",
    "            if DigitListener.winner == None:\n",
    "                DigitListener.winner = self.digit\n",
    "            self.threshold = DigitListener.threshold\n",
    "\n",
    "for i, digit in enumerate(digits):\n",
    "    beach.attach_listener(digit, DigitListener(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "The function 'predict' animate the beach with the features corresponding to a test digit and then it see which digit is stored in the class variable 'DigitListener.winner', that is the prediction given by the octopusal network.\n",
    "\n",
    "In the last cell we iterate over 250 test digits and calculate how many predictions are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index, dataset, show=False):\n",
    "    item = dataset.get_item(index)\n",
    "    label = item.label\n",
    "    if show: print(f\"Label: {label}\")\n",
    "    beach.animate(item.where, iterations=10, show=False, freeze_connections=True)\n",
    "    winner = DigitListener.winner\n",
    "    if show: print(f\"Winner: {winner}\")\n",
    "    beach.night()\n",
    "    return winner == label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 4\n",
      "Winner: 4\n",
      "Correct: True\n"
     ]
    }
   ],
   "source": [
    "correct = predict(9, mnist_data.train, show=True)\n",
    "print(f\"Correct: {correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 250\n",
      "\n",
      "  100% [=================================================================] Time elapsed: 180.82s\n",
      "\n",
      "Correct: 86.40%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from progress_bar import ProgressBar\n",
    "\n",
    "correct = 0\n",
    "\n",
    "start = 0\n",
    "count = 250\n",
    "\n",
    "print(f\"Test samples: {count}\\n\")\n",
    "\n",
    "pb = ProgressBar(count)\n",
    "time_start = time.time()\n",
    "\n",
    "for i in range(start, start + count):\n",
    "    result = predict(i, mnist_data.test, show=False)\n",
    "    if result == True:\n",
    "        correct += 1\n",
    "    pb += 1\n",
    "\n",
    "time_elapsed = time.time() - time_start\n",
    "print(f\" Time elapsed: {time_elapsed:.2f}s\")\n",
    "del pb\n",
    "\n",
    "print(f\"Correct: {correct / count * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "I don't know if the use of the convolutional base has the greater part of the merit but I think that it's quite a good result anyway. The algorithm is still not optimized but seems to me that it has good perception skills. In addition to perception it has also other qualities has seen in the [previous notebook](https://nbviewer.jupyter.org/github/marconunnari/octopusal_networks/blob/master/OctopusalNetworks.ipynb).\n",
    "\n",
    "\n",
    "If you have feedbacks or ideas feel free to contact me at hello@marconunnari.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: right\"><i>Marco Nunnari<br>May 2018</i></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
