{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist with octopusal connector\n",
    "\n",
    "In the [previous notebook](https://nbviewer.jupyter.org/github/marconunnari/octopusal_networks/blob/master/Mnist.ipynb) I used [octopusal networks](https://nbviewer.jupyter.org/github/marconunnari/octopusal_networks/blob/master/OctopusalNetworks.ipynb) to recognize the handwritten digits contained in the MNIST database. The problems was that it took more than 5 minutes to train the algorithm on just 500 training examples and the accuracy on 250 test examples was of 86%.\n",
    "\n",
    "I then figured out that the only features of the octopusal networks necessary to recognize the digits was the soreness of the tentacles. So I abstracted the soreness in numpy arrays and the result is terribly faster. It now takes around 2 seconds to train on 60000 training examples and get 94.63% accuracy on 10000 test examples. All on CPU.\n",
    "\n",
    "It is still dependent on the convolutional base and in retrospective it is a very easy approach to which probably someone has arrived before me. It could be useful for transfer learning if we get a general convolutional base or some similar system that extract features.\n",
    "\n",
    "Beside that it on the side of performance and usefulness doesn't have any advantages on neural networks, the only relevant thing is that it is compatible with the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OctopusalConnector import OctopusalConnector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional base\n",
    "\n",
    "Here I use a convolutional base trained with a neural network to extract the main features from the images. So that the input of the vectorized octopusal networks will be a set of specific features rather than the actual pixels.\n",
    "\n",
    "The main result of this extraction is an array of activations for each images. This array will contain `1` where the convolutional base outputs more than a certain threshold and `0` where the convolutional base outputs less than the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from progress_bar import ProgressBar\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.models import load_model\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "model = load_model('./cnn_minst.h5')\n",
    "layer_name = 'flatten_1'\n",
    "conv_base = Model(inputs=model.input,\n",
    "                  outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "data = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activations(conv_base, images, threshold):\n",
    "    images_mod = images.reshape((images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "    features = conv_base.predict(images_mod, verbose=1)\n",
    "    features = features * 100\n",
    "    features = features.astype(int)\n",
    "    features = features > threshold\n",
    "    features = features.astype(int)\n",
    "    return features\n",
    "\n",
    "    \n",
    "def extract_features(features_extractor, data, threshold=60):\n",
    "    (train_images, train_labels), (test_images, test_labels) = data\n",
    "    print('Extracting train features')\n",
    "    train_features = extract_activations(conv_base, train_images, threshold)\n",
    "    print('Extracting test features')\n",
    "    test_features = extract_activations(conv_base, test_images, threshold)\n",
    "    print()\n",
    "    return (train_features, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train features\n",
      "60000/60000 [==============================] - 9s 142us/step\n",
      "Extracting test features\n",
      "10000/10000 [==============================] - 1s 141us/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract train and test features\n",
    "(train_images, train_labels), (test_images, test_labels) = data\n",
    "(train_features, test_features) = extract_features(conv_base, data, threshold=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create an array of length 10 for each digit. This array consists of all `0` except a `1` in the position corresponding digit. To be clear for the digit 2 the array will be `[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_digit(digit):\n",
    "    result = np.zeros(10)\n",
    "    result[digit] = 1\n",
    "    return result\n",
    "\n",
    "def create_digits():\n",
    "    zero = create_digit(0)\n",
    "    one = create_digit(1)\n",
    "    two = create_digit(2)\n",
    "    three = create_digit(3)\n",
    "    four = create_digit(4)\n",
    "    five = create_digit(5)\n",
    "    six = create_digit(6)\n",
    "    seven = create_digit(7)\n",
    "    eight = create_digit(8)\n",
    "    nine = create_digit(9)\n",
    "    digits = [zero, one, two, three, four, five, six, seven, eight, nine]\n",
    "    return digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the actual training. First we inititialize a numpy array of shape `(576, 10)` that represent the soreness of the tentacles. `576` is the number of octopuses (or the number of features extracted from the convolutional base). `10` is the number of tentacles that go from each 'octopus feature' to each 'octopus digit' (or simply the number of digits).\n",
    "\n",
    "Then for each digit in the training examples, we compute the outer product between the features extracted and the array correspond to the digit. With this we get an array with shape `(576, 10)` with ones only on the tentacles that go from the activated features to the digit. We call this array `soreness_increment` and we add this to the previous array of `soreness`, so that will increase the `soreness` of the tentacles that go from the activated features to the digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 60000\n",
      "  100% [=================================================================] Time elapsed: 1.86s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 60000\n",
    "\n",
    "digits = create_digits()\n",
    "\n",
    "connector = OctopusalConnector(576, 10)\n",
    "\n",
    "print(f\"Training examples: {count}\")\n",
    "pb = ProgressBar(count)\n",
    "time_start = time.time()\n",
    "\n",
    "for index in range(count):\n",
    "    digit = digits[train_labels[index]]\n",
    "    features = train_features[index]\n",
    "    \n",
    "    connector.train(features, digit)\n",
    "\n",
    "    pb += 1\n",
    "\n",
    "time_elapsed = time.time() - time_start\n",
    "print(f\" Time elapsed: {time_elapsed:.2f}s\")\n",
    "del pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "To make a prediction we convert the vector of activations extracted from the convolutional base to a column vector and then multiply it for the soreness. In this way we get an array of shape `(576, 10)` where there is only the `soreness` of the tentacles of the activated octopuses (corresponding to the activated features). Then we sum the values on the columns obtaining an array of length 10 where each element is the sum of the `soreness` of all tentacles pointing to the the digit. We then see which digits are the more connected to the activated features.\n",
    "\n",
    "The argument `tolerance` indicates how many indexes we extract, if for example `tolerance = 2` we treat as predictions the two most connected digits. The default value is `1` to get only one firm prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d111e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction correct: True\n"
     ]
    }
   ],
   "source": [
    "def predict(index, tolerance=1):\n",
    "    features = test_features[index]\n",
    "    output = connector.predict(features)\n",
    "    predictions = list(np.argpartition(output, -2)[-tolerance:])\n",
    "    label = test_labels[index]\n",
    "    return label in predictions\n",
    "\n",
    "def show_image(image, label):\n",
    "    plt.title(f'Image: {label}')\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "\n",
    "index = 1\n",
    "show_image(test_images[index], test_labels[index])\n",
    "correct = predict(index, tolerance=2)\n",
    "print(f'Prediction correct: {correct}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "To compute the accuracy of the model we loop over each digit in the test dataset and we count how many predictions are correct. The argument `count` indicates how many test samples we consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(count, tolerance=1):\n",
    "    correct = 0\n",
    "    print(f\"Test samples: {count}\\n\")\n",
    "    pb = ProgressBar(count)\n",
    "    time_start = time.time()\n",
    "    for i in range(count):\n",
    "        result = predict(i, tolerance=tolerance)\n",
    "        if result == True:\n",
    "            correct += 1\n",
    "        pb += 1\n",
    "    time_elapsed = time.time() - time_start\n",
    "    print(f\" Time elapsed: {time_elapsed:.2f}s\")\n",
    "    del pb\n",
    "    print(f\"Correct: {correct / count * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tolerance 1\n",
    "\n",
    "With `tolerance = 1` we get 94.63% accuracy on 10000 test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 10000\n",
      "\n",
      "  100% [=================================================================] Time elapsed: 0.54s\n",
      "\n",
      "Correct: 94.63%\n"
     ]
    }
   ],
   "source": [
    "accuracy(10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tolerance 2\n",
    "\n",
    "With `tolerance = 2` we get 98.32% accuracy on 10000 test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 10000\n",
      "\n",
      "  100% [=================================================================] Time elapsed: 0.56s\n",
      "\n",
      "Correct: 98.32%\n"
     ]
    }
   ],
   "source": [
    "accuracy(10000, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: right\"><i>Marco Nunnari<br>May 2018</i></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
